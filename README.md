ğŸ“˜ BeyondChats AI Response Evaluator

A lightweight but complete evaluation engine built for the BeyondChats AI Evaluation Intern Task.
This project scores chatbot outputs based on:

Relevance â†’ How closely the AIâ€™s answer matches the userâ€™s query

Completeness â†’ How well the answer aligns with available context

Hallucination â†’ Whether the model invents information not found in context

Latency â†’ Total evaluation time

Cost Estimate â†’ Approximate (mock) inference cost

The evaluator uses semantic similarity (Sentence Transformers) to generate real-time scoring.

ğŸš€ Features
âœ… Relevance Scoring

Measures semantic similarity between the latest user query and the AI response.

âœ… Completeness Scoring

Checks how much of the AI response is grounded in the provided context chunks.

âœ… Hallucination Detection

Detects mismatches or fabricated information by measuring similarity against context.

âœ… Latency Measurement

Computes total evaluation time in milliseconds.

âœ… Plug-and-Play JSON Loader

Accepts:

chat.json

context.json (BeyondChats format)

ğŸ“ Project Structure
beyondchats-ai-evaluator/
â”‚
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chat.json
â”‚   â”œâ”€â”€ context.json
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ loader.py
    â”œâ”€â”€ similarity.py
    â””â”€â”€ scoring.py

ğŸ”§ Installation

Clone the repo:

git clone https://github.com/<your-username>/beyondchats-ai-evaluator
cd beyondchats-ai-evaluator


Install dependencies:

pip install -r requirements.txt

ğŸ“Œ Usage

Run the evaluator with:

python evaluate.py --chat data/chat.json --context data/context.json


Example output:

=== Evaluation Report ===
relevance: 0.25
completeness: 0.67
hallucination: 0.51
latency_ms: 687.456
cost_estimate_usd: 0.00001

ğŸ§  How the Evaluation Works
1ï¸âƒ£ Extract User Query

Pulls the latest user message from:

"conversation_turns"

2ï¸âƒ£ Extract AI Response

BeyondChats returns:

final_response: [ "sentence1", "sentence2" ]


Evaluator merges it into one string.

3ï¸âƒ£ Load Context Chunks

Extracts all "text" fields from vector_data.

Missing texts are safely skipped to avoid errors.

4ï¸âƒ£ Compute Semantic Scores

Uses all-MiniLM-L6-v2:

Cosine similarity for relevance

Cosine similarity vs context for completeness

1 - similarity for hallucination

5ï¸âƒ£ Output JSON-like metrics

Human-readable + easily parseable.

ğŸ“Š Why This Approach?

Fast execution (<1 second)

Cheap (local inference)

No external API dependency

Deterministic results

Clean code for easy extension

ğŸ§ª Example: Detecting a Hallucination

If the model claims:

"We offer subsidized rooms inside the clinic."

â€¦but this does not exist in the context vectors, the hallucination score rises (0.5+).
This is exactly what your sample evaluation output showed.

ğŸ‘¨â€ğŸ’» Intern Task Requirements â€” Covered
Requirement	Status
Load chat + context JSON	âœ…
Extract user query	âœ…
Extract AI response	âœ…
Parse vector context	âœ…
Compute relevance	âœ…
Compute completeness	âœ…
Detect hallucinations	âœ…
Measure latency	âœ…
Produce final clean score object	âœ…
Easy to run	âœ…
Clean code	âœ…

ğŸ“¬ Author

Built by --Najad
As part of the BeyondChats Intern Task.

â­ If you found this helpful, star the repository!
